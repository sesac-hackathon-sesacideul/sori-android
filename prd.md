# 📝 프로덕트 요구사항 정의서 (PRD)

## 1. 개요 (Overview)

| 항목 | 내용 |
| :--- | :--- |
| **제품 명칭** | [cite_start]청각 장애인을 위한 실시간 대화 및 환경 소리 비서 어플 (Contextual Interpreter) [cite: 4] |
| **팀 명** | [cite_start]셋싹이들 [cite: 2] |
| **팀 구성원** | [cite_start]정건희, 주연우, 허준서 [cite: 2] |
| **제품 비전** | [cite_start]청각 장애인의 삶을 근본적으로 재설계하고 안전하고 자율적인 생활 환경을 보장하는 AI 기반 혁신 솔루션 [cite: 30] |

---

## 2. 제안 배경 및 목적 (Background & Goals)

### 2.1. 해결하고자 하는 문제 (Problem Statement)
* [cite_start]**정보 격차 및 안전 사각지대 심화:** 기존의 보조 기술은 잔존 청력 보조에 집중되어 [cite: 19] [cite_start]비언어적 환경 소리 인지 능력이 여전히 취약하며 [cite: 20][cite_start], 특히 생명과 직결된 소리(경적, 사이렌, 비상벨)의 방향, 긴급성, 맥락 파악에 근본적인 한계가 존재합니다[cite: 21].
* [cite_start]**소통의 질적 한계 및 심리적 피로 가중:** 대화 상황에서 문자 통역/자막에 의존할 경우, 상대방의 감정 톤, 뉘앙스 등 비언어적 정보가 누락되어 [cite: 24] [cite_start]원활한 사회적 상호작용을 저해하고 [cite: 25] [cite_start]심리적 피로와 사회적 소외감을 가중시킵니다[cite: 26].
* [cite_start]**기존 보조 기술의 한계:** 시장 기술은 대부분 단순한 소리 인식 또는 일대일 자막 변환 수준에 머물러 있어 [cite: 28][cite_start], 청각 장애인이 환경을 주도적으로 인지하고 능동적으로 대처하도록 돕는 지능형 맥락 해석 기능이 미흡한 상태입니다[cite: 29].

### 2.2. 기대 효과 (Expected Outcomes)
* [cite_start]**소리 공백 해소 및 독립적인 생활 환경 구축:** 생활 필수 소리(초인종, 전화 알림, 가스레인지 타이머 등)를 명확히 인지하게 되어 [cite: 84] [cite_start]타인의 도움 없이도 일상 가사를 안전하고 자율적으로 수행하는 독립성을 향상시킵니다[cite: 85].
* [cite_start]**불안감 감소 및 환경 통제감 회복:** 소리의 종류와 방향을 실시간 시각적으로 확인하면서 [cite: 87][cite_start], 환경에 대한 통제감을 회복하고 심리적 안정감을 얻습니다[cite: 87].
* [cite_start]**대화 맥락 이해를 통한 소통 피로도 감소:** AI가 대화의 감정 톤과 핵심 의도를 요약해 줌으로써 [cite: 88][cite_start], 오해를 줄이고 대화에 집중해야 했던 인지적 피로를 크게 낮춥니다[cite: 89].

---

## 3. 핵심 기능 요구사항 (Core Feature Requirements)

[cite_start]본 서비스는 환경 안전 인지와 대화 맥락 해석이라는 두 가지 핵심 AI 기능으로 구현됩니다[cite: 8].

### 3.1. 환경 안전 인지 기능
| 기능 ID | 기능 명칭 | 요구사항 및 설명 | 기반 기술/데이터 |
| :--- | :--- | :--- | :--- |
| **ENV-001** | 소리 분류 및 감지 | [cite_start]위험 소리(사이렌, 경적, 비상벨)와 일상 필수 소리(초인종, 물 끓는 소리)를 정확하게 감지 및 분류해야 함[cite: 9, 34]. | [cite_start]위급상황 음성/음향 데이터 (AI Hub) [cite: 6] [cite_start]/ 경량화 된 SED 모델 [cite: 51] |
| **ENV-002** | 음원 위치 추정 (DOA) | [cite_start]소리가 발생한 **방향과 거리**를 정확하게 계산하고 시각화해야 함[cite: 10, 38]. | [cite_start]음원 위치 추정 (DOA) 기술 [cite: 10, 38] [cite_start]/ 마이크 어레이 연동 [cite: 38] |
| **ENV-003** | 실시간 안전 알림 | [cite_start]사용자에게 "(오른쪽 3m) 경적 소리!"와 같이 **구체적이고 즉각적인 안전 알림**을 제공해야 함[cite: 11]. | - |
| **ENV-004** | 소음 환경 강건성 | [cite_start]소음 환경 속에서 비상 소리 분리 성능을 극대화해야 함[cite: 52]. | [cite_start]소음 환경 음성인식 데이터 (AI Hub) [cite: 52] |

### 3.2. 대화 맥락 해석 기능
| 기능 ID | 기능 명칭 | 요구사항 및 설명 | 기반 기술/데이터 |
| :--- | :--- | :--- | :--- |
| **DIA-001** | 실시간 자동 음성 인식 (ASR) | [cite_start]대화 내용을 **실시간 텍스트로 변환**하여 지연 없이 자막을 제공해야 함[cite: 12]. [cite_start]소음 환경에서의 강건성 확보가 중요함[cite: 35]. | [cite_start]소음 환경 음성인식 데이터 (AI Hub) [cite: 6] [cite_start]/ 고성능 ASR 모델 (Whisper 또는 유사 오픈소스) [cite: 54] |
| **DIA-002** | 텍스트 기반 감정 분석 | [cite_start]상대방의 **감정 톤**을 분석하고 아이콘이나 경고 메시지(예: "(분노), 상대방이 격앙되었습니다")를 함께 표시하여 소통의 질을 높여야 함[cite: 13, 14, 37]. | [cite_start]텍스트 기반 감정 분류 모델 [cite: 13] [cite_start]/ Hugging Face Transformers [cite: 55] |
| **DIA-003** | 대화 핵심 요약 | [cite_start]긴 대화의 **핵심 의도를 NLP 기반 요약 모델로 추출**하여 청각 장애인의 인지적 피로를 낮추도록 지원해야 함[cite: 14, 37]. | [cite_start]NLP 기반 요약 모델 [cite: 14] [cite_start]/ Hugging Face Transformers [cite: 55] |

---

## 4. 아키텍처 및 구현 기술 (Architecture & Technology)

### 4.1. 기술 스택 요약
| 기술 영역 | 핵심 기술/모델 | 활용 데이터 |
| :--- | :--- | :--- |
| **음성 인식** | [cite_start]고성능 ASR 모델 (Whisper 등) [cite: 54] | [cite_start]소음 환경 음성인식 데이터 [cite: 35] |
| **환경 소리** | [cite_start]Sound Event Detection (SED) 모델 [cite: 43] | [cite_start]위급상황 음성/음향 데이터 [cite: 34] |
| **위치 추정** | [cite_start]음원 위치 추정 (DOA) 기술 [cite: 43, 53] | - |
| **맥락 해석** | [cite_start]NLP 기반 감정 분석 및 요약 모델 [cite: 37, 44] | [cite_start]Hugging Face Transformers 라이브러리 내 사전 학습 모델 [cite: 55] |

### 4.2. 서비스 동작 흐름
1.  [cite_start]**소리 수집:** 스마트폰 또는 웨어러블 디바이스의 마이크를 통해 주변 소리(오디오 스트림) 수집[cite: 41].
2.  [cite_start]**소리 분리:** AI 엔진이 소리를 **환경 소리**와 **대화 음성**으로 정확하게 분리하여 각 전문 AI 모듈로 전달[cite: 42].
3.  [cite_start]**처리 및 해석:** 각 AI 모듈(SED, DOA, ASR, NLP)이 독립적으로 소리 및 텍스트를 분석하여 맥락 정보를 생성[cite: 43, 44].
4.  [cite_start]**출력:** AI가 생성한 모든 맥락 정보는 단순 자막을 넘어, 경고 아이콘, 방향 화살표, 감정 이모지, 차별화된 진동 패턴 등의 **시각적 및 촉각적 알림**으로 변환되어 사용자에게 실시간 출력[cite: 46].

---

## 5. 사용자 경험 (UX/UI) 요구사항

* [cite_start]**입력 방식:** 사용자가 휴대하는 스마트폰이나 전용 웨어러블 디바이스의 마이크를 통해 주변 소리를 수집해야 함[cite: 41].
* [cite_start]**다중 정보 전달:** 환경 및 대화 정보를 시각적 및 촉각적 알림으로 변환하여 전달해야 하며 [cite: 46][cite_start], 이를 통해 청각 장애인이 환경에 대한 완전한 인지 능력과 통제감을 확보하도록 지원해야 함[cite: 47].
    * [cite_start]**환경 알림:** 소리의 종류, **방향 화살표**, 경고 아이콘, 거리 정보 등을 시각화하여 제공[cite: 11, 46]. (페이지 5의  참고)
    * [cite_start]**대화 알림:** 실시간 자막, 상대방의 감정 톤을 나타내는 **감정 이모지** 또는 경고 메시지, 긴 대화의 **핵심 요약**을 제공[cite: 13, 14, 46].
    * [cite_start]**촉각 알림:** 맥락 정보에 따라 **차별화된 진동 패턴**을 출력[cite: 46].

---

## 6. 성공 지표 (Success Metrics)

* **기술적 정확도:**
    * 소리 분류 정확도 (위험/필수 소리 감지)
    * DOA 정확도 (소리 방향 및 거리 추정)
    * ASR 인식률 (WER)
    * 감정 분류 및 요약의 핵심 의도 유지율
* **사용자 만족도:**
    * [cite_start]청각 장애인의 환경 통제감 회복 및 불안감 감소율[cite: 86, 87].
    * [cite_start]대화 시 인지적 피로도 감소율[cite: 89].
    * [cite_start]타인과의 상호작용 자연스러움 만족도[cite: 90].
* **서비스 활용도:**
    * 일일/월간 활성 사용자 수 (DAU/MAU) 및 핵심 기능 사용 빈도.