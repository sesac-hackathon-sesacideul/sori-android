package com.misterjerry.test01.ui

import android.app.Application
import android.content.Intent
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import androidx.lifecycle.AndroidViewModel
import androidx.lifecycle.viewModelScope
import com.misterjerry.test01.data.AudioClassifierHelper
import com.misterjerry.test01.data.ConversationItem
import com.misterjerry.test01.data.SoundEvent
import com.misterjerry.test01.data.SoundRepository
import com.misterjerry.test01.data.Urgency
import com.misterjerry.test01.util.VibrationHelper
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.SharingStarted
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.combine
import kotlinx.coroutines.flow.stateIn
import kotlinx.coroutines.launch
import com.misterjerry.test01.data.SoundSettings
import com.misterjerry.test01.data.VibrationPattern

data class MainUiState(
    val soundEvents: List<SoundEvent> = emptyList(),
    val conversationHistory: List<ConversationItem> = emptyList(),
    val isListening: Boolean = false,
    val soundSettings: SoundSettings = SoundSettings()
)


class MainViewModel(application: Application) : AndroidViewModel(application) {
    private val soundRepository = SoundRepository()
    // Remove ConversationRepository as we will generate real data
    // private val conversationRepository = ConversationRepository()

    private val _conversationHistory = MutableStateFlow<List<ConversationItem>>(emptyList())
    private val _isListening = MutableStateFlow(false)
    private val _soundSettings = MutableStateFlow(SoundSettings())

    private val speechRecognizer: SpeechRecognizer = SpeechRecognizer.createSpeechRecognizer(application)
    // private val audioClassifierHelper = AudioClassifierHelper(application) // Moved to Service
    private val vibrationHelper = VibrationHelper(application)

    init {
        // ... (SpeechRecognizer init code remains same) ...
        
        // Listen to audio classification results
        // Listen to audio classification results from EventBus
        // We now observe SoundEventBus.soundEvents directly in uiState, 
        // but we might still need to handle specific one-off logic if any.
        // For now, the list update is handled by the Bus and Service.
        
        // If we need to trigger vibration for foreground, we can still listen here OR 
        // rely on the Service to vibrate (which it now does for all).
        // However, the Service vibrates for Medium/High. 
        // The original ViewModel logic checked settings. 
        // Since we moved detection to Service, Service handles vibration.
        // We can remove the duplicate vibration logic here to avoid double vibration.

        // Listen to real-time events for Foreground Vibration
        viewModelScope.launch {
            com.misterjerry.test01.data.SoundEventBus.eventFlow.collect { event ->
                // Only handle if we are in foreground (though logic is in VM, VM is active when UI is active usually)
                // But VM can survive config changes. 
                // We rely on SoundEventBus.isForeground to be sure, or just rely on the fact that 
                // if the user is looking at the screen, they want feedback.
                // Actually, Service handles background. VM handles foreground.
                
                if (com.misterjerry.test01.data.SoundEventBus.isForeground) {
                    val settings = _soundSettings.value
                    val urgencySetting = when (event.urgency) {
                        Urgency.HIGH -> settings.highUrgency
                        Urgency.MEDIUM -> settings.mediumUrgency
                        Urgency.LOW -> settings.lowUrgency
                    }

                    if (urgencySetting.isEnabled) {
                        vibrationHelper.vibrate(urgencySetting.vibrationPattern)
                    }
                }
            }
        }
    }

    // ... (SpeechRecognizer methods remain same) ...

    fun startEnvironmentMode() {
        val intent = Intent(getApplication(), com.misterjerry.test01.service.SoundDetectionService::class.java)
        if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.O) {
            getApplication<Application>().startForegroundService(intent)
        } else {
            getApplication<Application>().startService(intent)
        }
    }

    fun stopEnvironmentMode() {
        val intent = Intent(getApplication(), com.misterjerry.test01.service.SoundDetectionService::class.java)
        getApplication<Application>().stopService(intent)
    }

    // handleSoundClassification is no longer needed in ViewModel as Service handles creation and Bus handles state.
    // However, if we want to support "Low Urgency" vibration settings which Service doesn't handle (Service only does Med/High),
    // we might need to keep some logic. 
    // But the user request was about background.
    // For consistency, let's assume Service handles all detection-related side effects for now, 
    // or we accept that foreground vibration settings might be bypassed by Service's simple logic.
    // Given the task "Fix Notification Navigation...", let's focus on the state.
    
    // We can remove handleSoundClassification entirely if we trust the Bus state.


    // We need to replace the repository flow with a local flow
    // Use SoundEventBus.soundEvents instead of local flow


    private val recognitionIntent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
        putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
        putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ko-KR")
        putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
    }

    init {
        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onReadyForSpeech(params: Bundle?) {}
            override fun onBeginningOfSpeech() {}
            override fun onRmsChanged(rmsdB: Float) {}
            override fun onBufferReceived(buffer: ByteArray?) {}
            override fun onEndOfSpeech() {
                _isListening.value = false
            }

            override fun onError(error: Int) {
                _isListening.value = false
                // Handle error if needed
            }

            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                if (!matches.isNullOrEmpty()) {
                    val text = matches[0]
                    addConversationItem(text)
                }
            }

            override fun onPartialResults(partialResults: Bundle?) {}
            override fun onEvent(eventType: Int, params: Bundle?) {}
        })
    }

    val uiState: StateFlow<MainUiState> = combine(
        com.misterjerry.test01.data.SoundEventBus.soundEvents,
        _conversationHistory,
        _isListening,
        _soundSettings,
    ) { sounds, history, isListening, settings ->
        MainUiState(
            soundEvents = sounds,
            conversationHistory = history,
            isListening = isListening,
            soundSettings = settings
        )
    }.stateIn(
        scope = viewModelScope,
        started = SharingStarted.WhileSubscribed(5000),
        initialValue = MainUiState()
    )

    fun startListening() {
        viewModelScope.launch(Dispatchers.Main) {
            _isListening.value = true
            speechRecognizer.startListening(recognitionIntent)
        }
    }

    fun stopListening() {
        viewModelScope.launch(Dispatchers.Main) {
            _isListening.value = false
            speechRecognizer.stopListening()
        }
    }

    private fun addConversationItem(text: String) {
        viewModelScope.launch {
            // 1. Add item immediately with loading state
            val tempId = System.currentTimeMillis()
            val tempItem = ConversationItem(
                id = tempId,
                speaker = "ìƒëŒ€ë°©",
                text = text,
                emotion = "",
                emotionLabel = "",
                isUser = false,
                timestamp = java.text.SimpleDateFormat("a h:mm", java.util.Locale.KOREA).format(java.util.Date()),
                isLoading = true
            )
            
            _conversationHistory.value = _conversationHistory.value + tempItem

            // 2. Analyze emotion
            val emotionLabel = analyzeEmotionWithGpt(text)
            val emotionEmoji = when (emotionLabel) {
                "ê¸ì •" -> "ðŸ˜ƒ"
                "ë¶€ì •" -> "ðŸ˜ "
                "ë†€ëžŒ" -> "ðŸ˜²"
                "ìŠ¬í””" -> "ðŸ˜¢"
                "ê³µí¬" -> "ðŸ˜¨"
                "ê±±ì •" -> "ðŸ˜Ÿ"
                else -> "ðŸ˜"
            }

            // 3. Update item with result
            val updatedList = _conversationHistory.value.map { item ->
                if (item.id == tempId) {
                    item.copy(
                        emotion = emotionEmoji,
                        emotionLabel = emotionLabel,
                        isLoading = false
                    )
                } else {
                    item
                }
            }
            _conversationHistory.value = updatedList
        }
    }

    private suspend fun analyzeEmotionWithGpt(text: String): String {
        return try {
            val prompt = """
                ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•´ì„œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½', 'ë†€ëžŒ', 'ìŠ¬í””', 'ê³µí¬', 'ê±±ì •' ì¤‘ í•˜ë‚˜ë¡œë§Œ ëŒ€ë‹µí•´ì¤˜.
                ê° ê°ì •ì˜ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ì•„:
                - ê¸ì •: ê¸°ì¨, í–‰ë³µ, ë™ì˜, ì¹­ì°¬, ê°ì‚¬ (ì˜ˆ: "ì •ë§ ì¢‹ì•„", "ê³ ë§ˆì›Œ")
                - ë¶€ì •: í™”ë‚¨, ì§œì¦, ë¹„íŒ, ê±°ì ˆ, ë¶ˆë§Œ (ì˜ˆ: "ì‹«ì–´", "ê·¸ë§Œí•´")
                - ë†€ëžŒ: ì¶©ê²©, ë¯¿ê¸° íž˜ë“¦, ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™© (ì˜ˆ: "ì •ë§?", "í—")
                - ìŠ¬í””: í›„íšŒ, ì‹¤ë§, ë¹„íƒ„, ìš°ìš¸ (ì˜ˆ: "ë„ˆë¬´ ìŠ¬í¼", "ì•„ì‰¬ì›Œ")
                - ê³µí¬: ë¬´ì„œì›€, ìœ„í˜‘, ë‹¤ê¸‰í•¨ (ì˜ˆ: "ë„ì™€ì¤˜", "ë¬´ì„œì›Œ")
                - ê±±ì •: ë¶ˆì•ˆ, ê·¼ì‹¬, ìƒëŒ€ë°©ì˜ ì•ˆë¶€ë¥¼ ë¬»ê±°ë‚˜ ì—¼ë ¤í•¨ (ì˜ˆ: "ê´œì°®ì•„?", "ì¡°ì‹¬í•´")
                - ì¤‘ë¦½: ê°ì •ì´ ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ” ì‚¬ì‹¤ ì „ë‹¬, ë‹¨ìˆœ ì§ˆë¬¸ (ì˜ˆ: "ì§€ê¸ˆ ëª‡ ì‹œì•¼?", "ë°¥ ë¨¹ì—ˆì–´")

                í…ìŠ¤íŠ¸: $text
            """.trimIndent()
            val request = com.misterjerry.test01.data.api.ChatRequest(
                messages = listOf(
                    com.misterjerry.test01.data.api.Message(role = "user", content = prompt)
                )
            )
            val response = com.misterjerry.test01.data.api.RetrofitClient.instance.getChatCompletion(request)
            val content = response.choices.firstOrNull()?.message?.content?.trim() ?: "ì¤‘ë¦½"
            
            // Validate response just in case
            if (content in listOf("ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½", "ë†€ëžŒ", "ìŠ¬í””", "ê³µí¬", "ê±±ì •")) content else "ì¤‘ë¦½"
        } catch (e: Exception) {
            e.printStackTrace()
            // Fallback to heuristic analysis
            analyzeEmotion(text)
        }
    }

    private fun analyzeEmotion(text: String): String {
        return when {
            text.contains("í™”ë‚˜") || text.contains("ì§œì¦") -> "ë¶€ì •"
            text.contains("í–‰ë³µ") || text.contains("ì¢‹ì•„") || text.contains("ì‚¬ëž‘") -> "ê¸ì •"
            text.contains("ë†€ë¼") || text.contains("í—‰") -> "ë†€ëžŒ"
            text.contains("ìŠ¬í¼") || text.contains("ìš°ìš¸") -> "ìŠ¬í””"
            text.contains("ë¬´ì„œ") || text.contains("ê³µí¬") -> "ê³µí¬"
            text.contains("ê±±ì •") || text.contains("ë¶ˆì•ˆ") || text.contains("ê·¼ì‹¬") || text.contains("ê´œì°®ì•„") -> "ê±±ì •"
            else -> "ì¤‘ë¦½"
        }
    }

    fun updateSoundSettings(newSettings: SoundSettings) {
        _soundSettings.value = newSettings
    }

    fun clearSoundEvents() {
        // _soundEventsFlow.value = emptyList()
        // To implement clear, we should add a clear method to SoundEventBus
        com.misterjerry.test01.data.SoundEventBus.clearEvents()
    }

    override fun onCleared() {
        super.onCleared()
        speechRecognizer.destroy()
    }
}
